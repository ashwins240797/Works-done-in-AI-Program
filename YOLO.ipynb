{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujKZuHQYnQXR"
   },
   "source": [
    "## **Problem Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3q9LTwFnt16X"
   },
   "source": [
    "# **Object Identification Using YOLOv3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTyNZJIUozkp"
   },
   "source": [
    "Detect objects in the image using pretrained YOLO on COCO dataset that consists of 80 objects with labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "La_09cTKoxCl"
   },
   "source": [
    "## **Objective**\n",
    "Detecting the objects correctly using a pretrained dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0y7WNhOycAV"
   },
   "source": [
    "### **Directories**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkImuEbOyUcu"
   },
   "source": [
    "We are going to use 3 directories:\n",
    "\n",
    "* **yolo-coco/**: This holds pretrained model files on the COCO dataset. Credit: *Darknet*\n",
    "\n",
    "* **images/**: This holds 4 images for testing and evaluation \n",
    "\n",
    "* **output/**: This will hold output that is processed by YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VkbWvZRa0iTL"
   },
   "source": [
    "    Note: Open the yolo.py file to edit it for desired object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7Ud7qhkldxk"
   },
   "source": [
    "### **Install DarkFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFZiLoUeleBT"
   },
   "outputs": [],
   "source": [
    "#Cloning DarkFlow (ensure that git and gitbash is intalled)\n",
    "git clone https://github.com/thtrieu/darkflow\n",
    "\n",
    "#Creating environment\n",
    "conda create -n darkflow-env python=3.6\n",
    "\n",
    "#Activating environment\n",
    "source activate darkflow-env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9X_uAoZlePn"
   },
   "source": [
    "### **Install TesorFlow, Cython, and Numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIOSkYnLlefJ"
   },
   "outputs": [],
   "source": [
    "conda install tensorflow-gpu cython numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xvHg5zb5BU5"
   },
   "source": [
    "### **Install OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ceDc5RT5FUV"
   },
   "outputs": [],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OAG_28b45Sro"
   },
   "source": [
    "    Note: \"pip\" should be installed in the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db0zrsFb0NYy"
   },
   "source": [
    "### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imWIAn2jwdJs"
   },
   "outputs": [],
   "source": [
    "import numpy as nump\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdcKcf1A0EIC"
   },
   "source": [
    "### **Add and Run Flag Arguments**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xff2pM5n01K6"
   },
   "outputs": [],
   "source": [
    "Parse = argparse.ArgumentParser()\n",
    "\n",
    "#Detecting objects in the image using YOLO\n",
    "Parse.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"Input image path\")\n",
    "\n",
    "#Loading the YOLO files to perform object detection\n",
    "Parse.add_argument(\"-y\", \"--yolo\", required=True,\n",
    "\thelp=\"YOLO directory path\")\n",
    "\n",
    "#Filtering weak detections with minimum probability (one can use any value between 0 to 1)\n",
    "Parse.add_argument(\"-c\", \"--confidence\", type=float, default=0.4,\n",
    "\thelp=\"Filtering weak detections with minimum probability\")\n",
    "\n",
    "#Applying non-maxima suppression with a threshold value\n",
    "Parse.add_argument(\"-t\", \"--threshold\", type=float, default=0.3,\n",
    "\thelp=\"Applying non-maxima suppression with a threshold value\")\n",
    "\n",
    "args = vars(Parse.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9QIaYB9HO4X"
   },
   "source": [
    "### **Load the Class Labels from Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPMEH-6hHP-y"
   },
   "outputs": [],
   "source": [
    "labelsPath = os.path.sep.join([args[\"yolo\"], \"coco.names\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbyQ1hI-HkW5"
   },
   "source": [
    "### **Initialize Colors that Represent Class Label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgQN0OWmHkty"
   },
   "outputs": [],
   "source": [
    "nump.random.seed(40)\n",
    "COLORS = nump.random.randint(0, 255, size=(len(LABELS), 3),\n",
    "\tdtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkL6gbTlIlbZ"
   },
   "source": [
    "### **Derive Paths**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyQRNmP2I6HA"
   },
   "source": [
    "#### **Derive Paths to YOLO Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CBGX48TIlvy"
   },
   "outputs": [],
   "source": [
    "weightsPath = os.path.sep.join([args[\"yolo\"], \"yolov3.weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0867AnMqJFCP"
   },
   "source": [
    "#### **Derive Paths to Model Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDGkP3ELJNvk"
   },
   "outputs": [],
   "source": [
    "configPath = os.path.sep.join([args[\"yolo\"], \"yolov3.cfg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRzgCS5VJWKA"
   },
   "source": [
    "### **Load YOLO Object Detector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhKrvVXnJW8B"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZo5vDP_J5k3"
   },
   "source": [
    "### **Load and Send the Image via the Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBvxNH_wUR5P"
   },
   "outputs": [],
   "source": [
    "#1. Loading input image & extracting its dimension \n",
    "image = cv2.imread(args[\"image\"])\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "\n",
    "#2. Determining names of output layer from YOLO model\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "#3. Getting bounding boxes and associated probabilities by:\n",
    "  #a. constructing blob from input image\n",
    "blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
    "\tswapRB=True, crop=False)\n",
    "\n",
    "  #b. executing forward pass of the YOLO object detector\n",
    "net.setInput(blob)\n",
    "start = time.time()\n",
    "layerOutputs = net.forward(ln)\n",
    "end = time.time()\n",
    "\n",
    "#4. Projecting inference time on YOLO\n",
    "print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-mCurUZUblf"
   },
   "source": [
    "### **Initialize the List**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcFdokf-UyM8"
   },
   "outputs": [],
   "source": [
    "boxes = [] #Bounding boxes around the object\n",
    "confidences = [] #YOLO-assigned confidence value of an object\n",
    "classIDs = [] #Labels of detected objects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVq0U8dfKRCI"
   },
   "source": [
    "### **Populate Data in the List**\n",
    "    Note: List includes boxes, confindence, and classIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSrL69D2Ve-_"
   },
   "outputs": [],
   "source": [
    "#Looping every output\n",
    "for output in layerOutputs:\n",
    "\n",
    "\t#Looping every detections\n",
    "\tfor detection in output:\n",
    "\n",
    "\t\t#Extracting currently detected objects' class ID & confidence\n",
    "\t\tscores = detection[5:]\n",
    "\t\tclassID = nump.argmax(scores)\n",
    "\t\tconfidence = scores[classID]\n",
    "\n",
    "\t\t#Weeding out the weak predictions\n",
    "\t\tif confidence > args[\"confidence\"]:\n",
    "      \n",
    "\t\t\t#Scaling coordinates of bounding box to display them on original image\n",
    "\t\t\tbox = detection[0:4] * nump.array([W, H, W, H])\n",
    "\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n",
    "   \n",
    "\t\t\t#Using (x, y) coordinates to get top-left of bounding box\n",
    "\t\t\tx = int(centerX - (width / 2))\n",
    "\t\t\ty = int(centerY - (height / 2))\n",
    "   \n",
    "\t\t\t#Updating the list\n",
    "\t\t\tboxes.append([x, y, int(width), int(height)])\n",
    "\t\t\tconfidences.append(float(confidence))\n",
    "\t\t\tclassIDs.append(classID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_bdb3B5fUyW"
   },
   "source": [
    "### **Implement Non-Maxima Suppression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W12KstSMfZk1"
   },
   "outputs": [],
   "source": [
    "idxs = cv2.dnn.NMSBoxes(boxes, confidences, args[\"confidence\"], args[\"threshold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJcaKN5kfjCk"
   },
   "source": [
    "### **Draw NMS Boxes and Class Text on Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxl4UYX3fjQF"
   },
   "outputs": [],
   "source": [
    "#Ensuring the existence of at least one detection\n",
    "if len(idxs) > 0:\n",
    "\n",
    "\t#Looping the indexes\n",
    "\tfor i in idxs.flatten():\n",
    "   \n",
    "\t\t#Extracting coordinates of bounding box\n",
    "\t\t(x, y) = (boxes[i][0], boxes[i][1])\n",
    "\t\t(w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "\t\t#Drawing rectangles in bounding box and adding random colors\n",
    "\t\tcolor = [int(c) for c in COLORS[classIDs[i]]]\n",
    "\t\tcv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "\t\ttext = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
    "\t\tcv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wj8FqlX-k5zc"
   },
   "source": [
    "### **Display an Output Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vutivLMYk68U"
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0fP9FQxlLyw"
   },
   "source": [
    "### **Execute YOLO in the Terminal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6SLXef_QlXkR"
   },
   "outputs": [],
   "source": [
    "$ python yolo.py --image images/baggage_claim.jpg --yolo yolo-coco"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assisted Practice 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
